{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155edb8-6bcd-4dd0-909f-4f9974539e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1:NLTK \n",
    " Perform the following task using NLTK: Tokenize and tag some text, identify named entities, display a parse tre and find the ambiguity of the sentence using parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b97c02-b2bf-461b-9393-71f09b995ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removal: ['This', 'is', 'a', 'sample', 'sentence,', 'showing', 'off', 'the', 'stop', 'words', 'filtration.', 'Barack', 'Obama', 'was', 'the', '44th', 'President']\n",
      "Filtered words: ['sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.', 'Barack', 'Obama', '44th', 'President']\n",
      "Stemmed Words: ['run', 'ran', 'runner', 'easili', 'fairli']\n",
      "Lemmatized Words: ['running', 'ran', 'runner', 'easily', 'fairly']\n",
      "POS Tags: [('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sample', 'JJ'), ('sentence', 'NN'), (',', ','), ('showing', 'VBG'), ('off', 'RP'), ('the', 'DT'), ('stop', 'NN'), ('words', 'NNS'), ('filtration', 'NN'), ('.', '.'), ('Barack', 'NNP'), ('Obama', 'NNP'), ('was', 'VBD'), ('the', 'DT'), ('44th', 'CD'), ('President', 'NNP')]\n",
      "Named Entities: (S\n",
      "  This/DT\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  sample/JJ\n",
      "  sentence/NN\n",
      "  ,/,\n",
      "  showing/VBG\n",
      "  off/RP\n",
      "  the/DT\n",
      "  stop/NN\n",
      "  words/NNS\n",
      "  filtration/NN\n",
      "  ./.\n",
      "  (PERSON Barack/NNP Obama/NNP)\n",
      "  was/VBD\n",
      "  the/DT\n",
      "  44th/CD\n",
      "  President/NNP)\n",
      "\n",
      "Parse Tree for 'the cat sat on the mat':\n",
      "             S                     \n",
      "      _______|_______               \n",
      "     |               VP            \n",
      "     |        _______|___           \n",
      "     |       |           PP        \n",
      "     |       |    _______|___       \n",
      "     NP      |   |           NP    \n",
      "  ___|___    |   |        ___|___   \n",
      "Det      N   V   P      Det      N \n",
      " |       |   |   |       |       |  \n",
      "the     cat sat  on     the     mat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag, ne_chunk, CFG\n",
    "from nltk import bigrams\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords')\n",
    "nltk.download('brown')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Sample text for processing\n",
    "text = \"This is a sample sentence, showing off the stop words filtration. Barack Obama was the 44th President \"\n",
    "\n",
    " # Stopword Removal\n",
    "stop_words = set(stopwords.words('english'))  # Get the list of English stopwords\n",
    "print(\"Before removal:\", text.split())\n",
    "\n",
    "word_tokens = word_tokenize(text)  # Tokenizing\n",
    "filtered_words = [word for word in word_tokens if word.lower() not in stop_words]  # Filter out stopwordsprint(\"Filtered Words:\", filtered_words)\n",
    "print(\"Filtered words:\",filtered_words)\n",
    " # Stemming\n",
    "ps = PorterStemmer()\n",
    "words_for_stemming = [\"running\", \"ran\", \"runner\", \"easily\", \"fairly\"]\n",
    "stemmed_words = [ps.stem(word) for word in words_for_stemming]  # Apply stemming\n",
    "print(\"Stemmed Words:\", stemmed_words)\n",
    "\n",
    " # Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words_for_stemming]  # Lemmatizing words\n",
    "print(\"Lemmatized Words:\", lemmatized_words) # Named Entity Recognition (NER)\n",
    "\n",
    "tokens = word_tokenize(text)  # Tokenize words\n",
    "\n",
    "pos_tags = pos_tag(tokens)  # Perform POS tagging\n",
    "\n",
    "print(\"POS Tags:\", pos_tags)\n",
    "\n",
    "entities = ne_chunk(pos_tags)  # Perform Named Entity Recognition\n",
    "print(\"Named Entities:\", entities)\n",
    "\n",
    " # Define a simple CFG grammar and parse a sentence\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    " S -> NP VP\n",
    " NP -> Det N\n",
    " VP -> V PP\n",
    " PP -> P NP\n",
    " Det -> 'the'\n",
    " N -> 'cat' | 'mat'\n",
    " V -> 'sat'\n",
    " P -> 'on'\n",
    " \"\"\")\n",
    "parser = nltk.ChartParser(grammar)  # Create a parser using the grammar\n",
    "sentence = \"the cat sat on the mat\".split()  # Parse the sentence\n",
    "print(\"\\nParse Tree for 'the cat sat on the mat':\")\n",
    "for tree in parser.parse(sentence):\n",
    "    tree.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab08ff-8f5c-44a4-a953-0c1fa74b929d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
