{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97609daa-5259-4669-9c3a-2bcffd1aa602",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementation of decision rule-based NaÃ¯ve Bayes disambiguation method to find the sense of an\n",
    "ambiguous word with the given training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "990024f4-3b0e-46c5-8f70-c0d8f9e9638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prior Probabilities:\n",
      "  P(financial_institution) = 0.4286\n",
      "  P(shore) = 0.5714\n",
      "\n",
      " Conditional Probabilities with Laplace Smoothing:\n",
      "\n",
      "ðŸ”¸ For class 'financial_institution':\n",
      "  P(need|financial_institution) = 0.0800\n",
      "  P(went|financial_institution) = 0.0800\n",
      "  P(walked|financial_institution) = 0.0400\n",
      "  P(bank|financial_institution) = 0.1600\n",
      "  P(savings|financial_institution) = 0.0800\n",
      "  P(deposit|financial_institution) = 0.0800\n",
      "  P(manager|financial_institution) = 0.0800\n",
      "  P(money|financial_institution) = 0.1200\n",
      "  P(along|financial_institution) = 0.0400\n",
      "  P(sat|financial_institution) = 0.0400\n",
      "  P(full|financial_institution) = 0.0400\n",
      "  P(fish|financial_institution) = 0.0400\n",
      "  P(camped|financial_institution) = 0.0400\n",
      "  P(river|financial_institution) = 0.0400\n",
      "  P(fished|financial_institution) = 0.0400\n",
      "\n",
      "ðŸ”¸ For class 'shore':\n",
      "  P(need|shore) = 0.0345\n",
      "  P(went|shore) = 0.0345\n",
      "  P(walked|shore) = 0.0690\n",
      "  P(bank|shore) = 0.1724\n",
      "  P(savings|shore) = 0.0345\n",
      "  P(deposit|shore) = 0.0345\n",
      "  P(manager|shore) = 0.0345\n",
      "  P(money|shore) = 0.0345\n",
      "  P(along|shore) = 0.0690\n",
      "  P(sat|shore) = 0.0690\n",
      "  P(full|shore) = 0.0690\n",
      "  P(fish|shore) = 0.0690\n",
      "  P(camped|shore) = 0.0690\n",
      "  P(river|shore) = 0.1379\n",
      "  P(fished|shore) = 0.0690\n",
      "\n",
      "Prediction:\n",
      "  â†’ Predicted Sense: financial_institution\n",
      "  â†’ Log Probability: -16.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\adisa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Training data: \"bank\" used in two senses\n",
    "training_data = [\n",
    "    (\"I need to savings money in the bank\", \"financial_institution\"),\n",
    "    (\"I went to the bank to deposit money\", \"financial_institution\"),\n",
    "    (\"They sat on the bank and fished\", \"shore\"),\n",
    "    (\"We walked along the bank of the river\", \"shore\"),\n",
    "    (\"The river bank was full of fish\", \"shore\"),\n",
    "    (\"He is a well-known bank manager\", \"financial_institution\"),\n",
    "    (\"We camped on the bank of the river\", \"shore\"),\n",
    "]\n",
    "\n",
    "# Preprocessing function: remove stopwords, punctuation, lowercase\n",
    "def preprocess(sent):\n",
    "    sent = sent.replace('.', '')\n",
    "    tokens = word_tokenize(sent)\n",
    "    sw = set(stopwords.words('english'))\n",
    "    data = [t.lower() for t in tokens if t.isalpha() and t.lower() not in sw]\n",
    "    return data\n",
    "\n",
    "# Function to get prior and conditional probabilities\n",
    "def get_counts(training_data):\n",
    "    class_counts = Counter()\n",
    "    word_counts = {}\n",
    "    total_words = defaultdict(int)\n",
    "\n",
    "    for data, sense in training_data:\n",
    "        if sense not in word_counts:\n",
    "            word_counts[sense] = Counter()\n",
    "\n",
    "    for data, sense in training_data:\n",
    "        class_counts[sense] += 1\n",
    "        words = preprocess(data)\n",
    "        word_counts[sense].update(words)\n",
    "        total_words[sense] += len(words)\n",
    "\n",
    "    return class_counts, word_counts, total_words\n",
    "\n",
    "# Calculate probabilities and print them\n",
    "def print_probabilities(class_counts, word_counts, total_words):\n",
    "    total_sentences = sum(class_counts.values())\n",
    "    print(\" Prior Probabilities:\")\n",
    "    for sense in class_counts:\n",
    "        prior = class_counts[sense] / total_sentences\n",
    "        print(f\"  P({sense}) = {prior:.4f}\")\n",
    "\n",
    "    print(\"\\n Conditional Probabilities with Laplace Smoothing:\")\n",
    "    vocabulary = set()\n",
    "    for wc in word_counts.values():\n",
    "        vocabulary.update(wc.keys())\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    for sense in word_counts:\n",
    "        print(f\"\\nðŸ”¸ For class '{sense}':\")\n",
    "        for word in vocabulary:\n",
    "            prob = (word_counts[sense][word] + 1) / (total_words[sense] + V)\n",
    "            print(f\"  P({word}|{sense}) = {prob:.4f}\")\n",
    "\n",
    "# Test sentence classification\n",
    "def testing(test, class_counts, word_counts, total_words):\n",
    "    test_words = preprocess(test)\n",
    "    best_sense = None\n",
    "    max_prob = -np.inf\n",
    "    vocabulary = set()\n",
    "    for wc in word_counts.values():\n",
    "        vocabulary.update(wc.keys())\n",
    "    V = len(vocabulary)\n",
    "\n",
    "    for sense in class_counts:\n",
    "        sense_prob = np.log2(class_counts[sense] / sum(class_counts.values()))\n",
    "        words_prob = 0\n",
    "        for word in test_words:\n",
    "            word_prob = (word_counts[sense][word] + 1) / (total_words[sense] + V)\n",
    "            words_prob += np.log2(word_prob)\n",
    "        total_prob = sense_prob + words_prob\n",
    "        if total_prob > max_prob:\n",
    "            max_prob = total_prob\n",
    "            best_sense = sense\n",
    "\n",
    "    return best_sense, max_prob\n",
    "\n",
    "# Run the model\n",
    "class_counts, word_counts, total_words = get_counts(training_data)\n",
    "\n",
    "# Print all probabilities\n",
    "print_probabilities(class_counts, word_counts, total_words)\n",
    "\n",
    "# Classify test sentence\n",
    "test = \"She opened a savings account at the bank\"\n",
    "print(\"\\nPrediction:\")\n",
    "result, prob = testing(test, class_counts, word_counts, total_words)\n",
    "print(f\"  â†’ Predicted Sense: {result}\\n  â†’ Log Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3377a-de04-4a7f-b8f6-454ae9a5c023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
