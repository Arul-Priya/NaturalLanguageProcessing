{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b3a52-6ecc-402d-a865-b844bc81c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2: T-test and chi-square test to check whether a given sequence of words is a collocation or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4900492-36c7-4cae-830f-dc02feff14b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram count for ('New', 'York'): 1\n",
      "T-test for ('New', 'York'): 0.8461538461538461\n",
      "Chi-squared value for ('New', 'York') association: 4.653846153846153\n",
      "Chi-squared value for ('New', 'York') association: 5.041666666666666\n",
      "Chi-squared value for ('New', 'York') association: 5.887820512820512\n",
      "Chi-squared value for ('New', 'York') association: 5.958333333333332\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    " # Example data (you can modify this dataset as needed)\n",
    "data = {'text': [\"I visited New York\", \"It was a New great trip\", \"I love traveling\"]}\n",
    "df = pd.DataFrame(data)\n",
    " # Step 1: Combine all text data into a single list of words\n",
    "words = (' '.join(df['text'].tolist())).split()\n",
    " # Step 2: Compute bigrams\n",
    "bigram_d = Counter(bigrams(words))\n",
    "print(f\"Bigram count for ('New', 'York'):\", bigram_d[('New', 'York')])\n",
    " # Step 3: Calculate frequencies for words and bigrams\n",
    "count_dict = Counter(words)\n",
    "bigrams_list = list(bigrams(words))\n",
    "bigram_dict = Counter(bigrams_list)\n",
    "word1 = 'New'\n",
    "word2 = 'York'\n",
    "w1,w2=word1,word2\n",
    " # Frequency of the words and the bigram\n",
    "f_w1 = count_dict[word1]\n",
    "f_w2 = count_dict[word2]\n",
    "f_w1w2 = bigram_dict[(word1, word2)]\n",
    " # Total number of words\n",
    "n = len(words)\n",
    " # Step 4: Calculate t-test value\n",
    "num = (f_w1w2 / n) - (f_w1 * f_w2 / (n * n))\n",
    "den = math.sqrt((f_w1w2 / n) / n)\n",
    "t_test = num / den\n",
    "print(f\"T-test for ('New', 'York'): {t_test}\")\n",
    " # Step 5: Create a contingency table (2x2) for chi-squared test\n",
    "a = bigram_dict[(word1, word2)]  # Count of ('New', 'York')\n",
    "b = count_dict[word1] - a  # Count of words starting with 'New' but not 'York'\n",
    "c = count_dict[word2] - a  # Count of words starting with 'York' but not 'New'\n",
    "d = sum(count_dict.values()) - (a + b + c)  # Total words minus the counts for a, b, c\n",
    " # Step 6: Calculate expected values for chi-squared test\n",
    "E_a = (a + b) * (a + c) / (a + b + c + d)\n",
    "E_b = (a + b) * (b + d) / (a + b + c + d)\n",
    "E_c = (a + c) * (c + d) / (a + b + c + d)\n",
    "E_d = (c + d) * (b + d) / (a + b + c + d)\n",
    " # Step 7: Calculate chi-squared statistic\n",
    "l1 = [a, b, c, d]\n",
    "l2 = [E_a, E_b, E_c, E_d]\n",
    "chi2 = 0\n",
    "for i in range(4):\n",
    "    chi2 += (l1[i] - l2[i]) ** 2 / l2[i]\n",
    "    print(f\"Chi-squared value for ('New', 'York') association: {chi2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb08fd-87ac-49f9-a2c7-3fd11c9024ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
